{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7018e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cls_global import gen_khmer_text_image\n",
    "\n",
    "# ============================================\n",
    "# PART 1: Load data from text_process.text\n",
    "# ============================================\n",
    "print(\"Loading data from text_process.text...\")\n",
    "try:\n",
    "    with open(\"test_process.txt\", 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Split content into lines\n",
    "    lines = content.strip().split('\\n')\n",
    "    data = pd.DataFrame(lines, columns=['word'])\n",
    "    data = data[data['word'].str.strip() != '']  # Remove empty lines\n",
    "    data['category'] = \"Text Process\"\n",
    "    \n",
    "    print(f\"Loaded {len(data)} entries from text_process.text\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: text_process.text not found!\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading text_process.text: {e}\")\n",
    "    exit()\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n=== Data Summary ===\")\n",
    "print(f\"Total Data: {len(data)}\")\n",
    "\n",
    "# ============================================\n",
    "# PART 2: Font and Background Variants\n",
    "# ============================================\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Automatically load all .ttf fonts from the fonts folder\n",
    "fonts_folder = \"fonts\"\n",
    "fonts = glob.glob(os.path.join(fonts_folder, \"*.ttf\"))\n",
    "\n",
    "if len(fonts) == 0:\n",
    "    print(f\"Warning: No .ttf fonts found in '{fonts_folder}' folder!\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\n=== Fonts Loaded ===\")\n",
    "print(f\"Found {len(fonts)} fonts:\")\n",
    "for font in fonts:\n",
    "    print(f\"  - {os.path.basename(font)}\")\n",
    "\n",
    "font_sizes = [12, 16]\n",
    "\n",
    "bg_colors = [\n",
    "    (255, 255, 255, 255),  # White\n",
    "    (250, 249, 247, 255),  # Light yellow paper\n",
    "    (240, 240, 240, 255),  # Light grey\n",
    "    (245, 222, 179, 255)   # Brownish paper\n",
    "]\n",
    "\n",
    "noise_levels = [\"low\", \"medium\", \"high\", \"none\"]\n",
    "blur_levels = [0, 2, 3, 4]\n",
    "\n",
    "# ============================================\n",
    "# PART 3: Train/Valid/Test Split\n",
    "# ============================================\n",
    "if len(data) > 0:\n",
    "    train_valid, test = train_test_split(\n",
    "        data, \n",
    "        test_size=0.2, \n",
    "        stratify=data[\"category\"], \n",
    "        random_state=42\n",
    "    )\n",
    "    train, valid = train_test_split(\n",
    "        train_valid, \n",
    "        test_size=0.1, \n",
    "        stratify=train_valid[\"category\"], \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Split Summary ===\")\n",
    "    print(f\"Train: {len(train)}\")\n",
    "    print(f\"Valid: {len(valid)}\")\n",
    "    print(f\"Test: {len(test)}\")\n",
    "    \n",
    "    # ============================================\n",
    "    # PART 4: Generate Images\n",
    "    # ============================================\n",
    "    data_folder = \"data_v1\"\n",
    "    \n",
    "    # Generate training images\n",
    "    print(\"\\n=== Generating Training Images ===\")\n",
    "    for i, (index, row) in enumerate(train.iterrows(), 1):\n",
    "        font_size = random.choice(font_sizes)\n",
    "        font = random.choice(fonts)\n",
    "        bg = random.choice(bg_colors)\n",
    "        noise_level = random.choice(noise_levels)\n",
    "        blur_level = random.choice(blur_levels)\n",
    "        \n",
    "        gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"train\", \n",
    "            bg=bg, \n",
    "            noise_level=noise_level, \n",
    "            blur_level=blur_level,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        if i % 100 == 0 or i == len(train):\n",
    "            print(f\"{i} of {len(train)}: complete\")\n",
    "    \n",
    "    # Generate validation images\n",
    "    print(\"\\n=== Generating Validation Images ===\")\n",
    "    for i, (index, row) in enumerate(valid.iterrows(), 1):\n",
    "        font_size = random.choice(font_sizes)\n",
    "        font = random.choice(fonts)\n",
    "        bg = random.choice(bg_colors)\n",
    "        noise_level = random.choice(noise_levels)\n",
    "        blur_level = random.choice(blur_levels)\n",
    "        \n",
    "        gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"valid\", \n",
    "            bg=bg, \n",
    "            noise_level=noise_level, \n",
    "            blur_level=blur_level,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        if i % 100 == 0 or i == len(valid):\n",
    "            print(f\"{i} of {len(valid)}: complete\")\n",
    "    \n",
    "    # Generate testing images\n",
    "    print(\"\\n=== Generating Testing Images ===\")\n",
    "    for i, (index, row) in enumerate(test.iterrows(), 1):\n",
    "        font_size = random.choice(font_sizes)\n",
    "        font = random.choice(fonts)\n",
    "        bg = random.choice(bg_colors)\n",
    "        noise_level = random.choice(noise_levels)\n",
    "        blur_level = random.choice(blur_levels)\n",
    "        \n",
    "        gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"test\", \n",
    "            bg=bg, \n",
    "            noise_level=noise_level, \n",
    "            blur_level=blur_level,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        if i % 100 == 0 or i == len(test):\n",
    "            print(f\"{i} of {len(test)}: complete\")\n",
    "    \n",
    "    print(\"\\n=== Image Generation Complete ===\")\n",
    "    \n",
    "    # ============================================\n",
    "    # PART 5: Save Train/Valid/Test Labels\n",
    "    # ============================================\n",
    "    print(\"\\n=== Saving Label Files ===\")\n",
    "    \n",
    "    # Save train labels\n",
    "    train_labels = []\n",
    "    for index, row in train.iterrows():\n",
    "        train_labels.append(f\"train/{index+1}.png\\t{row['word']}\")\n",
    "    with open(f\"{data_folder}/train.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(train_labels))\n",
    "    print(f\"Saved {len(train_labels)} training labels to {data_folder}/train.txt\")\n",
    "    \n",
    "    # Save valid labels\n",
    "    valid_labels = []\n",
    "    for index, row in valid.iterrows():\n",
    "        valid_labels.append(f\"valid/{index+1}.png\\t{row['word']}\")\n",
    "    with open(f\"{data_folder}/valid.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(valid_labels))\n",
    "    print(f\"Saved {len(valid_labels)} validation labels to {data_folder}/valid.txt\")\n",
    "    \n",
    "    # Save test labels\n",
    "    test_labels = []\n",
    "    for index, row in test.iterrows():\n",
    "        test_labels.append(f\"test/{index+1}.png\\t{row['word']}\")\n",
    "    with open(f\"{data_folder}/test.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(test_labels))\n",
    "    print(f\"Saved {len(test_labels)} test labels to {data_folder}/test.txt\")\n",
    "    \n",
    "else:\n",
    "    print(\"No data available for splitting and image generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d082e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from jiwer import cer, wer\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Compose, RandomRotation, ToPILImage\n",
    "\n",
    "# ============================================\n",
    "# PART 1: Dataset Class\n",
    "# ============================================\n",
    "class KhmerTextDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, processor, transform=None, max_target_length=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.processor = processor\n",
    "        self.transform = transform\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = self.processor(images=image, return_tensors=\"pt\").pixel_values.squeeze()\n",
    "\n",
    "        # Tokenize label\n",
    "        labels = self.processor.tokenizer(\n",
    "            label, \n",
    "            padding=\"max_length\", \n",
    "            max_length=self.max_target_length, \n",
    "            truncation=True\n",
    "        ).input_ids\n",
    "\n",
    "        return {\"pixel_values\": image, \"labels\": torch.tensor(labels)}\n",
    "\n",
    "# ============================================\n",
    "# PART 2: Helper Functions\n",
    "# ============================================\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Load tab-separated data\"\"\"\n",
    "    data = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"image\", \"label\"])\n",
    "    return data\n",
    "\n",
    "def create_dataloader(data, root_dir, processor, batch_size=16, shuffle=True, max_length=128, transform=None):\n",
    "    \"\"\"Create DataLoader from dataset\"\"\"\n",
    "    dataset = KhmerTextDataset(data, root_dir, processor, max_target_length=max_length, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# ============================================\n",
    "# PART 3: Configuration\n",
    "# ============================================\n",
    "batch_size = 16\n",
    "max_length = 128\n",
    "data_path = \"data_v1\"\n",
    "epochs = 10\n",
    "\n",
    "# ============================================\n",
    "# PART 4: Load Datasets\n",
    "# ============================================\n",
    "print(\"Loading datasets...\")\n",
    "train_data = load_dataset(f\"{data_path}/train.txt\")\n",
    "valid_data = load_dataset(f\"{data_path}/valid.txt\")\n",
    "test_data = load_dataset(f\"{data_path}/test.txt\")\n",
    "\n",
    "print(\"\\n=== Dataset Summary ===\")\n",
    "print(f\"Train: {len(train_data)} samples\")\n",
    "print(f\"Valid: {len(valid_data)} samples\")\n",
    "print(f\"Test: {len(test_data)} samples\")\n",
    "print(\"\\nSample train data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# ============================================\n",
    "# PART 5: Load Model and Processor\n",
    "# ============================================\n",
    "print(\"\\n=== Loading TrOCR Model ===\")\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ============================================\n",
    "# PART 6: Create DataLoaders\n",
    "# ============================================\n",
    "print(\"\\n=== Creating DataLoaders ===\")\n",
    "transform = Compose([\n",
    "    Resize((384, 384)),  # Resize to match ViT input size\n",
    "    RandomRotation(degrees=5),  # Add slight rotation\n",
    "    ToTensor(),  # Convert to PyTorch Tensor\n",
    "    Normalize(mean=[0.5], std=[0.5])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    train_data, f\"{data_path}/train/\", processor, \n",
    "    batch_size=batch_size, max_length=max_length, transform=transform\n",
    ")\n",
    "valid_loader = create_dataloader(\n",
    "    valid_data, f\"{data_path}/valid/\", processor, \n",
    "    batch_size=batch_size, max_length=max_length, transform=transform\n",
    ")\n",
    "test_loader = create_dataloader(\n",
    "    test_data, f\"{data_path}/test/\", processor, \n",
    "    batch_size=batch_size, max_length=max_length, transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Valid batches: {len(valid_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "# ============================================\n",
    "# PART 7: Visualize Sample Batch\n",
    "# ============================================\n",
    "print(\"\\n=== Visualizing Sample Batch ===\")\n",
    "reverse_transform = ToPILImage()\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"\\nBatch {i + 1}:\")\n",
    "    print(\"Pixel Values Shape:\", batch[\"pixel_values\"].shape)\n",
    "    print(\"Labels Shape:\", batch[\"labels\"].shape)\n",
    "\n",
    "    # Show first image in batch\n",
    "    label = batch[\"labels\"][0]\n",
    "    decoded_label = processor.tokenizer.decode(label.tolist(), skip_special_tokens=True)\n",
    "    print(f\"Decoded Label: {decoded_label}\")\n",
    "\n",
    "    pixel_values = batch[\"pixel_values\"][0]\n",
    "    image = reverse_transform(pixel_values)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Label: {decoded_label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    if i == 2:  # Show only first 3 batches\n",
    "        break\n",
    "\n",
    "# ============================================\n",
    "# PART 8: Training Setup\n",
    "# ============================================\n",
    "print(\"\\n=== Training Setup ===\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "cer_scores = []\n",
    "wer_scores = []\n",
    "\n",
    "# ============================================\n",
    "# PART 9: Training Loop\n",
    "# ============================================\n",
    "print(\"\\n=== Starting Training ===\")\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs} - Training\")\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    training_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_predictions = []\n",
    "    all_references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Validation\")\n",
    "        for batch in tqdm(valid_loader, desc=\"Validation\"):\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels.to(device))\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            # Decode predictions and references\n",
    "            predicted_ids = torch.argmax(outputs.logits, dim=-1)\n",
    "            predictions = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "            references = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            all_predictions.extend(predictions)\n",
    "            all_references.extend(references)\n",
    "\n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    validation_losses.append(avg_val_loss)\n",
    "\n",
    "    # Calculate CER and WER\n",
    "    cer_score = cer(all_references, all_predictions)\n",
    "    wer_score = wer(all_references, all_predictions)\n",
    "    cer_scores.append(cer_score)\n",
    "    wer_scores.append(wer_score)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, CER: {cer_score:.4f}, WER: {wer_score:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# PART 10: Plot Training Results\n",
    "# ============================================\n",
    "print(\"\\n=== Plotting Results ===\")\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "# Training and Validation Loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs_range, training_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(epochs_range, validation_losses, label=\"Validation Loss\", marker='s')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# CER and WER\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs_range, cer_scores, label=\"CER\", marker='o')\n",
    "plt.plot(epochs_range, wer_scores, label=\"WER\", marker='s')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"CER and WER over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PART 11: Save Model\n",
    "# ============================================\n",
    "print(\"\\n=== Saving Model ===\")\n",
    "model.save_pretrained(\"khmer_text_recognition_model_v3\")\n",
    "processor.save_pretrained(\"khmer_text_recognition_processor_v3\")\n",
    "print(\"Model and processor saved successfully!\")\n",
    "\n",
    "# ============================================\n",
    "# PART 12: Test the Model\n",
    "# ============================================\n",
    "print(\"\\n=== Testing Model ===\")\n",
    "# Load saved model and processor\n",
    "processor = TrOCRProcessor.from_pretrained(\"khmer_text_recognition_processor_v3\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"khmer_text_recognition_model_v3\")\n",
    "model.to(device)\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_preds, test_refs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # Generate predictions\n",
    "        outputs = model.generate(pixel_values, max_new_tokens=128)\n",
    "        decoded_preds = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "        decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        test_preds.extend(decoded_preds)\n",
    "        test_refs.extend(decoded_labels)\n",
    "\n",
    "# Calculate CER and WER\n",
    "test_cer = cer(test_refs, test_preds)\n",
    "test_wer = wer(test_refs, test_preds)\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\n=== Sample Predictions ===\")\n",
    "for i, (pred, ref) in enumerate(zip(test_preds[:10], test_refs[:10])):\n",
    "    print(f\"\\n{i+1}.\")\n",
    "    print(f\"Prediction: {pred}\")\n",
    "    print(f\"Reference:  {ref}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Display overall metrics\n",
    "print(\"\\n=== Overall Test Metrics ===\")\n",
    "print(f\"Character Error Rate (CER): {test_cer:.4f}\")\n",
    "print(f\"Word Error Rate (WER): {test_wer:.4f}\")\n",
    "print(\"\\n=== Training Complete ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
